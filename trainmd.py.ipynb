{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d5b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ee9af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd05b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = r\"P:\\Face-Mask-Detection\\dataset\"\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "750d6268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae17d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P:\\anaconda3\\lib\\site-packages\\PIL\\Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = load_img(img_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "        data.append(image)\n",
    "        labels.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7794a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8415ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8344ce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0307a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80d6f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3649679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4877b814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ee1cdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 92s 901ms/step - loss: 0.4142 - accuracy: 0.8368 - val_loss: 0.1419 - val_accuracy: 0.9896\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 84s 885ms/step - loss: 0.1460 - accuracy: 0.9604 - val_loss: 0.0732 - val_accuracy: 0.9922\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 88s 928ms/step - loss: 0.0936 - accuracy: 0.9769 - val_loss: 0.0517 - val_accuracy: 0.9909\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 87s 913ms/step - loss: 0.0730 - accuracy: 0.9829 - val_loss: 0.0433 - val_accuracy: 0.9935\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 85s 890ms/step - loss: 0.0681 - accuracy: 0.9792 - val_loss: 0.0381 - val_accuracy: 0.9935\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 85s 890ms/step - loss: 0.0558 - accuracy: 0.9875 - val_loss: 0.0415 - val_accuracy: 0.9896\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 86s 903ms/step - loss: 0.0556 - accuracy: 0.9835 - val_loss: 0.0337 - val_accuracy: 0.9935\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 88s 924ms/step - loss: 0.0467 - accuracy: 0.9871 - val_loss: 0.0335 - val_accuracy: 0.9922\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 76s 795ms/step - loss: 0.0476 - accuracy: 0.9868 - val_loss: 0.0281 - val_accuracy: 0.9935\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 83s 875ms/step - loss: 0.0484 - accuracy: 0.9858 - val_loss: 0.0309 - val_accuracy: 0.9948\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 85s 890ms/step - loss: 0.0399 - accuracy: 0.9888 - val_loss: 0.0279 - val_accuracy: 0.9935\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 86s 902ms/step - loss: 0.0357 - accuracy: 0.9924 - val_loss: 0.0263 - val_accuracy: 0.9935\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 83s 869ms/step - loss: 0.0373 - accuracy: 0.9911 - val_loss: 0.0258 - val_accuracy: 0.9935\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 83s 874ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 0.0235 - val_accuracy: 0.9948\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 88s 929ms/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 0.0226 - val_accuracy: 0.9948\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 90s 949ms/step - loss: 0.0363 - accuracy: 0.9868 - val_loss: 0.0229 - val_accuracy: 0.9948\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 92s 970ms/step - loss: 0.0306 - accuracy: 0.9924 - val_loss: 0.0230 - val_accuracy: 0.9948\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 93s 980ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 0.0232 - val_accuracy: 0.9935\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 85s 888ms/step - loss: 0.0260 - accuracy: 0.9908 - val_loss: 0.0253 - val_accuracy: 0.9935\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 84s 888ms/step - loss: 0.0296 - accuracy: 0.9904 - val_loss: 0.0234 - val_accuracy: 0.9948\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BS,\n",
    "\tepochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1ca9feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "24/24 [==============================] - 11s 396ms/step\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e122c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxs = np.argmax(predIdxs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fc7f368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       0.99      1.00      0.99       383\n",
      "without_mask       1.00      0.99      0.99       384\n",
      "\n",
      "    accuracy                           0.99       767\n",
      "   macro avg       0.99      0.99      0.99       767\n",
      "weighted avg       0.99      0.99      0.99       767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "\ttarget_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83f7c215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving mask detector model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"mask_detector.model\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c54661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
